{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403\n",
      "Forbidden\n",
      "403\n",
      "Forbidden\n",
      "403\n",
      "Forbidden\n",
      "403\n",
      "Forbidden\n",
      "403\n",
      "Forbidden\n",
      "403\n",
      "Forbidden\n",
      "403\n",
      "Forbidden\n",
      "403\n",
      "Forbidden\n",
      "403\n",
      "Forbidden\n",
      "403\n",
      "Forbidden\n",
      "save...\n",
      "第1条\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f9affe2edeff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'爬取完毕'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-f9affe2edeff>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mdatalist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgetData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbaseurl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0msavepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/Users/m/Desktop/豆瓣电影top250.xls'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0msaveData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatalist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msavepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-f9affe2edeff>\u001b[0m in \u001b[0;36msaveData\u001b[0;34m(datalist, savepath)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'第%d条'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatalist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0msheet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import urllib.request,urllib.error\n",
    "import xlwt\n",
    "\n",
    "\n",
    "def main():\n",
    "    baseurl='https://movie.douban.com/top250?start='\n",
    "    #爬取网页     \n",
    "    datalist=getData(baseurl)\n",
    "    savepath='/Users/m/Desktop/豆瓣电影top250.xls'\n",
    "    saveData(datalist,savepath)\n",
    "\n",
    "\n",
    "#     askURL(baseurl)\n",
    "\n",
    "#影片详情链接的规则\n",
    "findLink=re.compile(r'<a href=\"(.*?)\">')   #创建正则表达式对象，表示规则或者字符串的模式\n",
    "#影片图片\n",
    "findImgSrc=re.compile(r'<img.*src=\"(.*?)\"',re.S) #让换行符包括在字符中\n",
    "#影片片名\n",
    "findTitle=re.compile(r'<span class=\"title\">(.*?)</span>',re.S)\n",
    "#影片评分\n",
    "findRating=re.compile(r'<span class=\"rating_num\" property=\"v:average\">(.*?)</span>')\n",
    "#影片评价人数\n",
    "findJudge=re.compile(r'<span>(\\d*)人评价</span>')\n",
    "#影片概况\n",
    "findInq=re.compile(r'<span class=\"inq\">(.*?)</span>')\n",
    "#影片的相关内容\n",
    "findBd=re.compile(r'<p class=\"\">(.*?)</p>',re.S)\n",
    "\n",
    "def getData(baseurl): \n",
    "    datalist=[]\n",
    "    for i in range(0,10):\n",
    "        url=baseurl+str(i*25)\n",
    "        html=askURL(url)\n",
    "        #逐一解析数据（可以拿到网页的时候就解析）\n",
    "        soup=BeautifulSoup(html,\"html.parser\")\n",
    "        for item in soup.find_all('div',class_=\"item\"):\n",
    "#             print(item)    #测试：查看电影item的详细信息\n",
    "            data=[]    #保存一部电影的所有信息\n",
    "            item=str(item)\n",
    "        \n",
    "            #影片详情的链接\n",
    "            link=re.findall(findLink,item)[0]   #re库用来通过正则表达式查找指定字符串,[0]表示要找到的所有里的第一个\n",
    "            data.append(link)\n",
    "            #影片图片\n",
    "            img=re.findall(findImgSrc,item)[0]\n",
    "            data.append(img)\n",
    "            #影片标题\n",
    "            title=re.findall(findTitle,item)\n",
    "            if (len(title)==2):\n",
    "                ctitle=title[0]\n",
    "                data.append(ctitle)\n",
    "                otitle=title[1].replace('/','')   #去掉无关符号\n",
    "                data.append(otitle)\n",
    "            else:\n",
    "                data.append(title)\n",
    "                data.append(' ')   #为外文名留空，方便做表\n",
    "            #影片评分\n",
    "            rate=re.findall(findRating,item)[0]\n",
    "            data.append(rate)\n",
    "            \n",
    "            judgeNum=re.findall(findJudge,item)[0]\n",
    "            data.append(judgeNum)\n",
    "            \n",
    "            inq=re.findall(findInq,item)\n",
    "            if len(inq)!=0:\n",
    "                inq=inq[0].replace('。','')\n",
    "                data.append(inq)\n",
    "            else:\n",
    "                data.append(' ')    #留空\n",
    "                \n",
    "            bd=re.findall(findBd,item)[0]\n",
    "            bd=re.sub('<br(\\s+)?/>(\\s+)?',' ',bd)   #去掉<br/>\n",
    "            bd=re.sub('/',' ',bd)     #替换/\n",
    "            data.append(bd.strip())  #去掉前后空格\n",
    "            \n",
    "            datalist.append(data)   #把处理好的一部电影信息放入datalist\n",
    "#             print(link)\n",
    "#             print(img)\n",
    "#             print(title)\n",
    "#             print(rate)\n",
    "#     print(datalist)\n",
    "    return datalist \n",
    "\n",
    "#得到指定的一个网页\n",
    "def askURL(url):\n",
    "    head={\n",
    "        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.135 Safari/537.36'\n",
    "    }\n",
    "        \n",
    "     #用户代理：表示告诉服务器我们是什么类型的浏览器，本质上是告诉浏览器我们可以接受什么水平的文件内容\n",
    "    request=urllib.request.Request(url,headers=head)\n",
    "    html=''\n",
    "    try:\n",
    "        response=urllib.request.urlopen(request)\n",
    "        html=response.read().decode('utf-8')\n",
    "#         print(html)\n",
    "    except urllib.error.URLError as e:\n",
    "        if hasattr(e,'code'):\n",
    "            print(e.code)\n",
    "        if hasattr(e,'reason'):\n",
    "            print(e.reason)\n",
    "    return html\n",
    "            \n",
    "\n",
    "# #爬取网页  \n",
    "# def getData(baseurl):\n",
    "#     for i in range(10):\n",
    "#         url=baseurl+str(i*25)\n",
    "#         html=askURL(url)\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "#保存数据\n",
    "def saveData(datalist,savepath):\n",
    "    print('save...')\n",
    "    book=xlwt.Workbook(encoding='utf-8',style_compression=0)\n",
    "    sheet=book.add_sheet('豆瓣电影Top250', cell_overwrite_ok=True)\n",
    "    col=('电影详情链接','图片链接','影片中文名','影片外国名','评分','评价数','概况','相关信息')\n",
    "    for i in range(0,8):\n",
    "        sheet.write(0,i,col[i])   #列名\n",
    "    for i in range(0,250):\n",
    "        print('第%d条'%(i+1))\n",
    "        data=datalist[i]\n",
    "        for j in range(0,8):\n",
    "            sheet.write(i+1,j,data[j])\n",
    "    book.save(savepath)\n",
    "    \n",
    "if __name__=='__main__':\n",
    "    main()\n",
    "    print('爬取完毕')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
